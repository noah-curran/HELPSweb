

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>People and Topics &mdash; Purdue HELPS Laboratory  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Products" href="product.html" />
    <link rel="prev" title="Join the Team" href="join.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Purdue HELPS Laboratory
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="join.html">Join the Team</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">People and Topics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#fall-schedule">2019 Fall Schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topics">Topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#forest-inventory-analysis">Forest Inventory Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="#analysis-of-drone-video">Analysis of Drone Video</a></li>
<li class="toctree-l3"><a class="reference internal" href="#embedded-vision-1">Embedded Vision 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="#analyze-human-behavior-in-video">Analyze Human Behavior in Video</a></li>
<li class="toctree-l3"><a class="reference internal" href="#software-engineering-for-machine-learning">Software Engineering for Machine Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#crowdsourcing">Crowdsourcing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#image-database">Image Database</a></li>
<li class="toctree-l3"><a class="reference internal" href="#embedded-vision-2">Embedded Vision 2</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#faculty">Faculty</a></li>
<li class="toctree-l2"><a class="reference internal" href="#members">Members</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#graduate-students">Graduate Students</a></li>
<li class="toctree-l3"><a class="reference internal" href="#undergraduate-students-and-2019-summer-teams">Undergraduate Students and 2019 Summer Teams</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Image Database</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset-distinctiveness">Dataset Distinctiveness</a></li>
<li class="toctree-l4"><a class="reference internal" href="#crowdsourcing-for-data-bias">Crowdsourcing for Data Bias</a></li>
<li class="toctree-l4"><a class="reference internal" href="#forest-inventory">Forest Inventory</a></li>
<li class="toctree-l4"><a class="reference internal" href="#human-behavior">Human Behavior</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#alumni">Alumni</a></li>
<li class="toctree-l2"><a class="reference internal" href="#video-by-current-and-former-members">Video by Current and Former Members</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="product.html">Products</a></li>
<li class="toctree-l1"><a class="reference internal" href="currentmember.html">HOW TO (For Current Members)</a></li>
<li class="toctree-l1"><a class="reference internal" href="professionalism.html">Conduct and Professionalism</a></li>
<li class="toctree-l1"><a class="reference internal" href="funding.html">Sponsors and Collaborators</a></li>
<li class="toctree-l1"><a class="reference internal" href="labmachine.html">Lab Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="expectations.html">CAM2 Progress Evaluation Expectations</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Purdue HELPS Laboratory</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>People and Topics</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/people.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="people-and-topics">
<h1>People and Topics<a class="headerlink" href="#people-and-topics" title="Permalink to this headline">¶</a></h1>
<div class="section" id="fall-schedule">
<h2>2019 Fall Schedule<a class="headerlink" href="#fall-schedule" title="Permalink to this headline">¶</a></h2>
<p>All meetings are held in EE 013.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 14%" />
<col style="width: 20%" />
<col style="width: 29%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Time</p></th>
<th class="head"><p>Monday</p></th>
<th class="head"><p>Tuesday</p></th>
<th class="head"><p>Wednesday</p></th>
<th class="head"><p>Friday</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>11:00-12:00</p></td>
<td><p>Forest</p></td>
<td></td>
<td><p>Software Engineering</p></td>
<td><p>Image Database</p></td>
</tr>
<tr class="row-odd"><td><p>12:30-13:30</p></td>
<td></td>
<td><p>Human Behavior</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>13:30-14:30</p></td>
<td><p>Drone</p></td>
<td></td>
<td><p>Crowdsourcing</p></td>
<td><p>Embedded 2</p></td>
</tr>
<tr class="row-odd"><td><p>14:30-15:30</p></td>
<td><p>Embedded 1</p></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>15:30-16:30</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>17:30-18:20</p></td>
<td></td>
<td></td>
<td><p>VIP lecture (EE 129)</p></td>
<td></td>
</tr>
</tbody>
</table>
<p>Due to the large number of team mebers, it is not possible changing
the regular meeting time. If your schedule does not fit into a
particular team, you have to move to another team.</p>
</div>
<div class="section" id="topics">
<h2>Topics<a class="headerlink" href="#topics" title="Permalink to this headline">¶</a></h2>
<div class="section" id="forest-inventory-analysis">
<h3>Forest Inventory Analysis<a class="headerlink" href="#forest-inventory-analysis" title="Permalink to this headline">¶</a></h3>
<p>Use computer vision to calculate the sizes of trees (called diameter
at breath height, or DBH), recognize the species of trees, and their
locations.  For Fall 2019, the team has two major goals: (1) handle
multiple trees in a single frame and (2) handle trees in a nautral
forest.</p>
<p>The following images show the result from a distance sensor and the tree image (before and after denoising).</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/distanceimage01.png"><img alt="forest03" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/distanceimage01.png" style="width: 59%;" /></a> <a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/treeimage02.png"><img alt="forest04" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/treeimage02.png" style="width: 18%;" /></a> <a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/treeimage01.png"><img alt="forest05" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/treeimage01.png" style="width: 18%;" /></a></p>
<p>The following images show how the team measures the diameter at breath height.</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/measuretree01.jpeg"><img alt="forest00" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/measuretree01.jpeg" style="width: 35%;" /></a> <a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/measuretree02.jpeg"><img alt="forest01" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/measuretree02.jpeg" style="width: 20%;" /></a> <a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/measuretree03.jpeg"><img alt="forest02" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/measuretree03.jpeg" style="width: 35%;" /></a></p>
<p>Readings for new members:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.fia.fs.fed.us/">Forest Inventory and Analysis (FIA) Program of the U.S. Forest Service</a></p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/7109840">Forest Data Collection Using Terrestrial Image-Based Point Clouds From a Handheld Camera Compared to Terrestrial and Personal Laser Scanning</a></p></li>
<li><p><a class="reference external" href="https://www.mdpi.com/1999-4907/7/3/61">Estimation of Tree Stem Attributes Using Terrestrial Photogrammetry with a Camera Rig</a></p></li>
<li><p><a class="reference external" href="https://www.mdpi.com/1999-4907/10/8/643/htm">Development and Testing of a New Ground Measurement Tool to Assist in Forest GIS Surveys</a></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="analysis-of-drone-video">
<h3>Analysis of Drone Video<a class="headerlink" href="#analysis-of-drone-video" title="Permalink to this headline">¶</a></h3>
<p>This project creates computer vision solutions recognizing objects
captured by cameras mounted on drones.  In Fall 2019, the team will
create a set of video clips for the following purposes:</p>
<ul class="simple">
<li><p>Construct three-dimensional geometries of objects: The video clips
will capture cardboard boxes of different sizes, together with a
wide range of objects and several with known sizes.</p></li>
<li><p>Detect and track multiple moving objects: The clips include moving
objects.  The drone itself is also moving. The purpose is to
correctly identify these objects and track their movements.</p></li>
<li><p>Segmentation: Create pixel-wise labels of different objects.</p></li>
<li><p>Re-identify people: Determine whether the same person has been
before.</p></li>
</ul>
<p>This project is supported by <a class="reference external" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1925713">NSF CNS-1925713</a></p>
<p>Readings for new members:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1804.07437.pdf">Vision Meets Drones: A Challenge</a></p></li>
<li><p><a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Context_Encoding_for_CVPR_2018_paper.pdf">Context Encoding for Semantic Segmentation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1904.01400.pdf">Vehicle Re-identification in Aerial Imagery: Dataset and Approach</a></p></li>
<li><p><a class="reference external" href="https://www.spiedigitallibrary.org/journalArticle/Download?fullDOI=10.1117/1.JEI.28.2.023003&amp;casa_token=Rs6JtKyTL6cAAAAA:_5C4cfQ5XkKqoeFqiyXl7r-xNdDH27PTYeq52ag1Va8udjeU3ykDF2-6B082Fdqt9JQHioCPXjE">Airborne visual tracking and reidentification system</a></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="embedded-vision-1">
<h3>Embedded Vision 1<a class="headerlink" href="#embedded-vision-1" title="Permalink to this headline">¶</a></h3>
<p>Recent progress in computer vision has focused primarily in
general-purpose object detection using datasets with many (hundreds)
categories of objects (such as humans, dogs, vehicles, furniture,
buildings, etc.).  For many applications, however, the number of
possible objects can be limited. For example, inside an airport
terminal, elephants or eagles are not expected. This project will use
<strong>computer graphics</strong> to synthesize images and videos of these
scenarios. The synthesized data is used to train computer vision
running on embedded systems (also called <strong>edge devices</strong>).  Doing so
can reduce network traffic and make the system more
scalable. Moreover, sensitive information (such as human faces) may be
detected and protected before the data leaves the cameras.</p>
<p>Readings for new members:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1608.02192.pdf">Playing for Data: Ground Truth from Computer Games</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/content/pdf/10.1007%2Fs11263-018-1073-7.pdf">Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications</a></p></li>
<li><p><a class="reference external" href="https://www.researchgate.net/profile/Fei_Yue_Wang/publication/334390716_The_ParallelEye_Dataset_A_Large_Collection_of_Virtual_Images_for_Traffic_Vision_Research/links/5d270204a6fdcc2462d490c9/The-ParallelEye-Dataset-A-Large-Collection-of-Virtual-Images-for-Traffic-Vision-Research.pdf">The ParallelEye Dataset: A Large Collection of Virtual Images for Traffic Vision Research</a></p></li>
</ul>
</div>
<div class="section" id="analyze-human-behavior-in-video">
<h3>Analyze Human Behavior in Video<a class="headerlink" href="#analyze-human-behavior-in-video" title="Permalink to this headline">¶</a></h3>
<p>The purpose of this team is to use real-time video analytics to detect
dangerous behavior or safety violation in workplace (such as
factories), raise alerts to prevent injury, or provide post-event
analysis to prevent future occurrences. In Fall 2019, the team will
focus on solving these problems in an indoor
environment with multiple cameras:</p>
<ul class="simple">
<li><p>Where are the people (including re-identifying the same person in different cameras)?</p></li>
<li><p>Where does each person face?</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="software-engineering-for-machine-learning">
<h3>Software Engineering for Machine Learning<a class="headerlink" href="#software-engineering-for-machine-learning" title="Permalink to this headline">¶</a></h3>
<p>This project creates a process for developing <strong>reproducible</strong>
software used in machine learning. In Fall 2019, the team’s focus is
to create tools that faciliate code review. The tools analyze the
histories of version control repositories and identify</p>
<p>Readings</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/pdf/1905.02597.pdf">Explainable Software Bot Contributions: Case Study of Automated Bug Fixes</a></p></li>
<li><p><a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8330261">Automated Code Review via Software Repository Mining</a></p></li>
<li><p><a class="reference external" href="https://patentimages.storage.googleapis.com/2a/da/ad/e8fa817408f010/US20180275989A1.pdf">(Patent)Automated program code analysis and reporting</a></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="crowdsourcing">
<h3>Crowdsourcing<a class="headerlink" href="#crowdsourcing" title="Permalink to this headline">¶</a></h3>
<p>Computer vision is still not perfect and humans outperform computers
in many situations. This team builds computer tools (human interfaces)
for humans to identify unexpected properties (called “bias”) in data
used to train computer programs. These tools are computer games and
the players (crowds) describe the characteristics in the data.</p>
<p>Reading for new members:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.944.9518&amp;rep=rep1&amp;type=pdf">Unbiased look at dataset bias</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1602.07332">Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1505.00468">VQA: Visual Question Answering</a></p></li>
<li><p><a class="reference external" href="https://drive.google.com/file/d/1vuTRkuU9DLPI4zJvAWqRrYX2R7PlWUtS/view">Crowdsourcing in Computer Vision (Chapters 1 and 2)</a></p></li>
<li><p><a class="reference external" href="http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf">Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</a></p></li>
</ul>
<p><a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourcehome.png"><img alt="crowdsource03" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourcehome.png" style="width: 45%;" /></a> <a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourceexample.png"><img alt="crowdsource02" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourceexample.png" style="width: 45%;" /></a></p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourceposter.jpg"><img alt="crowdsource05" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourceposter.jpg" style="width: 45%;" /></a> <a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourceteam.jpg"><img alt="crowdsource04" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/crowdsourceteam.jpg" style="width: 45%;" /></a></p>
</div>
<hr class="docutils" />
<div class="section" id="image-database">
<h3>Image Database<a class="headerlink" href="#image-database" title="Permalink to this headline">¶</a></h3>
<p>This system integrates computer vision and database.  After the
objects in images are detected, the information is stored in a
database so that it is searchable.  The team has built a prototype of
the system processing multiple video streams simultaneously. The team
will focus on improving the performance (scalability) for lower
latency as well as investigating new storage systems.</p>
<p>Reading for new members:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1512.07108">Recent Advances in Convolutional Neural Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1804.02767">YOLOv3: An Incremental Improvement</a></p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="embedded-vision-2">
<h3>Embedded Vision 2<a class="headerlink" href="#embedded-vision-2" title="Permalink to this headline">¶</a></h3>
<p>This project investigates computer vision solutions that can perform
the following tasks in an embedded computer (small enough to be inside
a typical camera)</p>
<ul class="simple">
<li><p>Obtain aggregate information (such as the number of people and their genders)</p></li>
<li><p>Detect faces</p></li>
<li><p>Encrypt the faces before sending the data to storage</p></li>
</ul>
<p>The sensitive data (faces) never leaves the camera.  Only authorized
people with the decryption key can see the faces. The concept is
illustrated below.</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/embeddedprivacy.png"><img alt="embeddedprivacy" src="https://raw.githubusercontent.com/PurdueCAM2Project/HELPSweb/master/source/images/embeddedprivacy.png" style="width: 90%;" /></a></p>
<p>Readings for new members:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.mdpi.com/2076-3417/8/11/2222/htm">An Improved Neural Network Cascade for Face Detection in Large Scene Surveillance</a></p></li>
<li><p><a class="reference external" href="http://shuoyang1213.me/WIDERFACE/">WIDER FACE: A Face Detection Benchmark</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.08707">Optimizing the Trade-off between Single-Stage and Two-Stage Object Detectors using Image Difficulty Prediction</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.07737">PyramidBox: A Context-assisted Single Shot Face Detector</a></p></li>
<li><p><a class="reference external" href="https://www.mdpi.com/1424-8220/19/9/2158/pdf">Real-Time Multi-Scale Face Detector on Embedded Devices</a></p></li>
</ul>
</div>
</div>
<hr class="docutils" />
<div class="section" id="faculty">
<h2>Faculty<a class="headerlink" href="#faculty" title="Permalink to this headline">¶</a></h2>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 33%" />
<col style="width: 17%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://ag.purdue.edu/ProfileImages/dbarbara.jpg" src="https://ag.purdue.edu/ProfileImages/dbarbara.jpg" />
</td>
<td><p><a class="reference external" href="https://ag.purdue.edu/hla/LA/Pages/Profile.aspx?strAlias=dbarbara&amp;intDirDeptID=24">David Michael Barbarash</a></p>
<p>Landscape Architecture, Purdue</p>
</td>
<td><img alt="https://engineering.purdue.edu/ResourceDB/ResourceFiles/image92690" src="https://engineering.purdue.edu/ResourceDB/ResourceFiles/image92690" />
</td>
<td><p><a class="reference external" href="https://engineering.purdue.edu/ME/People/ptProfile?id=92669">Dave Capperlleri</a></p>
<p>Mechanical Engineering, Purdue</p>
</td>
</tr>
<tr class="row-even"><td><img alt="https://shuohanchen.files.wordpress.com/2019/02/shuohan-eps-converted-to.png?w=220&amp;h=300" src="https://shuohanchen.files.wordpress.com/2019/02/shuohan-eps-converted-to.png?w=220&amp;h=300" />
</td>
<td><p><a class="reference external" href="https://shuohanchen.com/">Shuo-Han Chen</a></p>
<p>Institute of Information Science, Academia Sinica</p>
</td>
<td><img alt="https://drive.google.com/uc?id=1EqxgXBuEQNiQ5pNVvg42AfWMFKByjKh1" src="https://drive.google.com/uc?id=1EqxgXBuEQNiQ5pNVvg42AfWMFKByjKh1" />
</td>
<td><p><a class="reference external" href="https://engineering.purdue.edu/ECE/People/ptProfile?resource_id=3355">Yung-Hsiang Lu</a></p>
<p>Electrical and Computer Engineering, Purdue</p>
</td>
</tr>
<tr class="row-odd"><td><img alt="http://www.stat.purdue.edu/images/Faculty/thumbnail/varao-t.jpg" src="http://www.stat.purdue.edu/images/Faculty/thumbnail/varao-t.jpg" />
</td>
<td><p><a class="reference external" href="http://www.stat.purdue.edu/people/faculty/varao">Vinayak Rao</a></p>
<p>Statistics, Purdue</p>
</td>
<td><img alt="https://drive.google.com/uc?id=19_-2sKwLTcjoBvjclB8tqlIA56k5QwUq" src="https://drive.google.com/uc?id=19_-2sKwLTcjoBvjclB8tqlIA56k5QwUq" />
</td>
<td><p><a class="reference external" href="https://ag.purdue.edu/fnr/Pages/profile.aspx?strAlias=shao">Guofan Shao</a></p>
<p>Professor,  Forestry and Natural Resources, Purdue</p>
</td>
</tr>
<tr class="row-even"><td><img alt="https://avatars1.githubusercontent.com/u/651504?s=460&amp;v=4" src="https://avatars1.githubusercontent.com/u/651504?s=460&amp;v=4" />
</td>
<td><p><a class="reference external" href="https://thiruvathukal.com">George K. Thiruvathukal</a></p>
<p>Computer Science, Loyola University Chicago.</p>
</td>
<td><img alt="http://www.stat.purdue.edu/~mdw/images/WardMFO.jpg" src="http://www.stat.purdue.edu/~mdw/images/WardMFO.jpg" />
</td>
<td><p><a class="reference external" href="http://www.stat.purdue.edu/~mdw/">Mark Daniel Ward</a></p>
<p>Statistics, Purdue</p>
</td>
</tr>
<tr class="row-odd"><td><img alt="https://ag.purdue.edu/ProfileImages/woeste.jpg" src="https://ag.purdue.edu/ProfileImages/woeste.jpg" />
</td>
<td><p><a class="reference external" href="https://ag.purdue.edu/fnr/Pages/profile.aspx?strAlias=woeste">Keith E. Woeste</a></p>
<p>Forestry and Natural Resources, Purdue</p>
</td>
<td><img alt="https://www.cs.purdue.edu/people/images/small/faculty/mingyin.jpg" src="https://www.cs.purdue.edu/people/images/small/faculty/mingyin.jpg" />
</td>
<td><p><a class="reference external" href="https://www.cs.purdue.edu/people/mingyin">Ming Yin</a></p>
<p>Computer Science, Purdue</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="members">
<h2>Members<a class="headerlink" href="#members" title="Permalink to this headline">¶</a></h2>
<div class="section" id="graduate-students">
<h3>Graduate Students<a class="headerlink" href="#graduate-students" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 75%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=1YunKydNN7OS_vvBubbME4UykfjNh1CgA" src="https://drive.google.com/uc?id=1YunKydNN7OS_vvBubbME4UykfjNh1CgA" />
</td>
<td><p>Abhinav Goel: Doctoral Student, Improve Neural Networks’ Energy Efficiency</p></td>
</tr>
<tr class="row-even"><td><img alt="https://drive.google.com/uc?id=1GzpDueX6W2e4sx0OGfKm51cru34jyEvp" src="https://drive.google.com/uc?id=1GzpDueX6W2e4sx0OGfKm51cru34jyEvp" />
</td>
<td><p>Sara Aghajanzadeh: Master Student, Detect Faces and Protect Privacy</p></td>
</tr>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=1kIYIrkXnICIb2odq5WWGlsdCYv4fTpVU" src="https://drive.google.com/uc?id=1kIYIrkXnICIb2odq5WWGlsdCYv4fTpVU" />
</td>
<td><p>Ryan Dailey: Master Student, Discover Network Cameras</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="undergraduate-students-and-2019-summer-teams">
<h3>Undergraduate Students and 2019 Summer Teams<a class="headerlink" href="#undergraduate-students-and-2019-summer-teams" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id1">
<h4>Image Database<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 33%" />
<col style="width: 17%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=1RWw0U_QwKhY8ZioiPdDmlN2_VEros3Zt" src="https://drive.google.com/uc?id=1RWw0U_QwKhY8ZioiPdDmlN2_VEros3Zt" />
</td>
<td><p><cite>Shunqiao Huang</cite></p>
<p>Leader</p>
</td>
<td></td>
<td><p><cite>Hojoung Jang</cite></p></td>
</tr>
<tr class="row-even"><td></td>
<td><p><cite>Akshay Pawar</cite></p></td>
<td></td>
<td><p><cite>Aditya Chakraborty</cite></p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p><cite>Lucas Wiles</cite></p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="dataset-distinctiveness">
<h4>Dataset Distinctiveness<a class="headerlink" href="#dataset-distinctiveness" title="Permalink to this headline">¶</a></h4>
<p>Identify the specific features (called distinctiveness) of
different visual dataset. Use one dataset with many labels to help
train machine models for another datasets with few labels.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 33%" />
<col style="width: 17%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=1yUr73JBTlTG0LMew8pqVXA5csNggmuOX" src="https://drive.google.com/uc?id=1yUr73JBTlTG0LMew8pqVXA5csNggmuOX" />
</td>
<td><p><cite>Ashley Kim</cite></p>
<p>Leader</p>
</td>
<td></td>
<td><p><cite>Damini  Rijhwani</cite></p></td>
</tr>
<tr class="row-even"><td><img alt="https://drive.google.com/uc?id=1Qu7L33SNwQtBw8Qx-4s-Fm9oIUq9v7G-" src="https://drive.google.com/uc?id=1Qu7L33SNwQtBw8Qx-4s-Fm9oIUq9v7G-" />
</td>
<td><p><cite>Kirthi Shankar  Sivamani</cite></p></td>
<td></td>
<td><p><cite>Esteban Gorostiaga</cite></p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p><cite>Shuhao  Xing</cite></p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="crowdsourcing-for-data-bias">
<h4>Crowdsourcing for Data Bias<a class="headerlink" href="#crowdsourcing-for-data-bias" title="Permalink to this headline">¶</a></h4>
<p>Use crowd (i.e., humans) to identify unintentional biases in visual
datasets.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 33%" />
<col style="width: 17%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=1BgdG9XYcrmdMtdSbePpp324jwdnwl_7p" src="https://drive.google.com/uc?id=1BgdG9XYcrmdMtdSbePpp324jwdnwl_7p" />
</td>
<td><p><cite>Xiao Hu</cite></p>
<p>Co-Leader</p>
</td>
<td><img alt="https://drive.google.com/uc?id=1t-krvZinKrSk1YT8MRl8R6xoPUHpF8H7" src="https://drive.google.com/uc?id=1t-krvZinKrSk1YT8MRl8R6xoPUHpF8H7" />
</td>
<td><p><cite>Haobo Wang</cite></p>
<p>Co-Leader</p>
</td>
</tr>
<tr class="row-even"><td><img alt="https://drive.google.com/uc?id=1GSO6wVspOBuu881yg-5Bg2E5xEA1gSMJ" src="https://drive.google.com/uc?id=1GSO6wVspOBuu881yg-5Bg2E5xEA1gSMJ" />
</td>
<td><p><cite>Kaiwen Yu</cite></p></td>
<td><img alt="https://drive.google.com/uc?id=1u5dbejyw-62y5x6UPKEtPo3DFd4AtYCc" src="https://drive.google.com/uc?id=1u5dbejyw-62y5x6UPKEtPo3DFd4AtYCc" />
</td>
<td><p><cite>Anirudh Vegesana</cite></p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p><cite>Somesh  Dube</cite></p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="forest-inventory">
<h4>Forest Inventory<a class="headerlink" href="#forest-inventory" title="Permalink to this headline">¶</a></h4>
<p>Use computer vision to calculate the sizes of trees
(called diameter at breath height, or DBH).</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 33%" />
<col style="width: 17%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=1GeeVgSnl4Fwf-rlIFlG5LuSohcMMIpTi" src="https://drive.google.com/uc?id=1GeeVgSnl4Fwf-rlIFlG5LuSohcMMIpTi" />
</td>
<td><p><cite>Nick Eliopoulos</cite></p></td>
<td><img alt="https://drive.google.com/uc?id=1WrLZtXkzgHDQbCC0XLX92C8a8rgS6yMd" src="https://drive.google.com/uc?id=1WrLZtXkzgHDQbCC0XLX92C8a8rgS6yMd" />
</td>
<td><p><cite>Yezhi Shen</cite></p></td>
</tr>
<tr class="row-even"><td></td>
<td><p><cite>Yuxin Zhang</cite></p></td>
<td></td>
<td><p><cite>Vaastav Arora</cite></p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p><cite>Minh Nguyen</cite></p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="human-behavior">
<h4>Human Behavior<a class="headerlink" href="#human-behavior" title="Permalink to this headline">¶</a></h4>
<p>Track human activities and understand how they use designed space.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 33%" />
<col style="width: 17%" />
<col style="width: 33%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><img alt="https://drive.google.com/uc?id=14FxQ_dr9836vXFBx1YknDQ0rn-QVZHWy" src="https://drive.google.com/uc?id=14FxQ_dr9836vXFBx1YknDQ0rn-QVZHWy" />
</td>
<td><p><cite>Mohamad Alani</cite></p></td>
<td><img alt="https://drive.google.com/uc?id=1bZxvHiZ-H7ACq55FpJQqbJgj8NZjZlcb" src="https://drive.google.com/uc?id=1bZxvHiZ-H7ACq55FpJQqbJgj8NZjZlcb" />
</td>
<td><p><cite>Peter Huang</cite></p></td>
</tr>
<tr class="row-even"><td></td>
<td><p><cite>Dhruv Swarup</cite></p></td>
<td></td>
<td><p><cite>Chau Minh Nguyen</cite></p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="section" id="alumni">
<h2>Alumni<a class="headerlink" href="#alumni" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="video-by-current-and-former-members">
<h2>Video by Current and Former Members<a class="headerlink" href="#video-by-current-and-former-members" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><iframe width="600" height = "400" src="https://www.youtube.com/embed/7Ao2zCYV9I8" frameborder="0" allowfullscreen></iframe><iframe width="600" height = "400" src="https://www.youtube.com/embed/1LGjSqQ953A" frameborder="0" allowfullscreen></iframe><iframe width="600" height = "400" src="https://www.youtube.com/embed/oPeKHUHpU2c" frameborder="0" allowfullscreen></iframe></div></blockquote>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Purdue HELPS Laboratory

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>